> build things from scratch. make your own inference engine that can support llama. Understand why and how it works. implement various architectures. Go back and read a few arxiv papers when you don't understand something and then read the citations.
> just build stuff


[x] make your inference engine support llama/mistral [4:30 AM 08/07/2024]
[ ] implement various archs
[ ] flash2 ??
[ ] tpu_splash??
[ ] MLA
[ ] NLA
[ ] done implement big guns 
[ ] finally get DSCv2 lite working??
[ ] profit???

goal 

to go from barebones whisper implementation to fully fleged DSCv2 lite implemation

wip notes for this 
https://ksagar.me/blog/mistral2DSCv2

refrence for DSCv2
https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct
